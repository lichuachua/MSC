{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9032139,"sourceType":"datasetVersion","datasetId":5444109},{"sourceId":9034096,"sourceType":"datasetVersion","datasetId":5445522},{"sourceId":9035446,"sourceType":"datasetVersion","datasetId":5446472},{"sourceId":9040340,"sourceType":"datasetVersion","datasetId":5450077},{"sourceId":9127679,"sourceType":"datasetVersion","datasetId":5510760},{"sourceId":9136837,"sourceType":"datasetVersion","datasetId":5517765},{"sourceId":9136849,"sourceType":"datasetVersion","datasetId":5517772},{"sourceId":9136906,"sourceType":"datasetVersion","datasetId":5517809}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BlipProcessor, BlipForConditionalGeneration\nfrom PIL import Image\nimport os\n\n# Load the image captioning model and processor\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\nmodel = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n\n# Directory containing images\nimage_dir = '/kaggle/input/cartoon-dataset-new/cartoon_dataset/'\n\n# Get all image files in the directory\nimage_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n\n# Load and process images\nfor image_file in image_files:\n    try:\n        # Construct the full path to the image\n        image_path = os.path.join(image_dir, image_file)\n        image = Image.open(image_path)\n        inputs = processor(images=image, return_tensors=\"pt\")\n\n        # Generate image caption\n        out = model.generate(**inputs)\n        caption = processor.decode(out[0], skip_special_tokens=True)\n\n        print(image_file, \"Generated caption:\", caption)\n    except Exception as e:\n        print(f\"Error processing {image_file}: {e}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-12T17:48:25.516631Z","iopub.execute_input":"2024-08-12T17:48:25.517981Z","iopub.status.idle":"2024-08-12T17:52:04.539550Z","shell.execute_reply.started":"2024-08-12T17:48:25.517931Z","shell.execute_reply":"2024-08-12T17:52:04.538305Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"6015056.jpg Generated caption: a girl looking at her reflection in the mirror\n6016425.jpg Generated caption: a woman in a black and red outfit\n6016555.jpg Generated caption: a girl in a blue dress holding an ice cream cone\n6014121.jpg Generated caption: a girl in a black outfit with a black bow\n6014813.jpg Generated caption: a girl with long brown hair and a blue dress\n6016836.jpg Generated caption: a girl with red hair and horns is posing in the air\n6015916.jpg Generated caption: a girl with blue hair and a black hat holding a large ax\n6015406.jpg Generated caption: a girl with long hair and a cat ears\n6016340.jpg Generated caption: a girl with long hair and a white shirt, wearing a purple vest and black shorts\n6016835.jpg Generated caption: a woman in a black and white outfit with a sword\n6015377.jpg Generated caption: a girl in a school uniform is standing in a hallway\n6014072.jpg Generated caption: a girl in a school uniform drinking a cup\n6015058.jpg Generated caption: a cat with a big smile and a big smile on her face\n6015060.jpg Generated caption: a sexy anime girl with red hair and blue eyes\n6016197.jpg Generated caption: a girl with long pink hair and a white dress\n6014137.jpg Generated caption: a girl in a red dress and a white shirt is holding a stick\n6015546.jpg Generated caption: a girl in a blue dress and a gray jacket\n6016679.jpg Generated caption: a girl in a uniform with a cat tail\n6015543.jpg Generated caption: a girl with blue hair and a blue hair, holding a gun\nError processing metadata.jsonl: cannot identify image file '/kaggle/input/cartoon-dataset-new/cartoon_dataset/metadata.jsonl'\n6016907.jpg Generated caption: a girl with red hair and blue eyes, wearing a purple dress\n6015326.jpg Generated caption: a girl with long hair and a purple dress\n6013788.jpg Generated caption: a woman in a pink outfit sitting on a couch\n6015740.jpg Generated caption: a girl in a black and white outfit\n6015324.jpg Generated caption: a girl in a pink dress and a pink dress with flowers\n6014098.jpg Generated caption: a girl in a pink outfit is laying on a bed\n6013787.jpg Generated caption: a girl with long pink hair and a white dress\n6015547.jpg Generated caption: a girl with blue hair and a black hat\n6015204.jpg Generated caption: a woman in a kimono kimono costume holding a sword\n6015690.jpg Generated caption: a woman in a kimono outfit holding a sword\n6015495.jpg Generated caption: a girl in a blue dress and a cat ears\n6016355.jpg Generated caption: a girl with green hair and a white shirt\n6016192.jpg Generated caption: a girl with long blonde hair and red shoes\n6014336.jpg Generated caption: a girl with long brown hair and a black dress\n6015896.jpg Generated caption: a girl in a swimsuit with a cat on her shoulder\n6013931.jpg Generated caption: a girl in a white dress and black stockings sitting on a bed\n6016245.jpg Generated caption: a girl in a school uniform\n6015898.jpg Generated caption: a girl with long hair and a pink dress\n6015727.jpg Generated caption: a girl with long black hair and blue eyes\n6014126.jpg Generated caption: a girl in a red dress and a purple hair is sitting on a couch\n6015194.jpg Generated caption: a cartoon girl in a gray top and black pants\n6014196.jpg Generated caption: a girl in a school uniform with long hair and a tie\n6016929.jpg Generated caption: a girl in a school uniform with long black hair and a white shirt\n6013975.jpg Generated caption: a girl with long hair and a red shirt\n6014195.jpg Generated caption: a girl with long hair and a tie\n6013889.jpg Generated caption: a girl with pink hair and glasses\n6015722.jpg Generated caption: a girl in a red outfit and a red hat\n6015906.jpg Generated caption: a girl with long hair and a blue dress, holding a cell phone\n6014523.jpg Generated caption: a girl in a dress and hat holding a balloon\n6014194.jpg Generated caption: a girl in a suit and tie holding a glass of orange juice\n6016291.jpg Generated caption: a girl in a kimono kimono\n6016870.jpg Generated caption: a woman in a long black dress standing on a hill\n6015545.jpg Generated caption: a girl with blue hair and a hat\n6016252.jpg Generated caption: two anime girls in yellow and blue outfits\n6015776.jpg Generated caption: a girl in a pink outfit and green hat\n6016191.jpg Generated caption: a girl with long hair and a flower in her hair\n6013882.jpg Generated caption: a girl in a black and white outfit\n6013859.jpg Generated caption: a girl in a white dress with a red bow and a spoon\n6015237.jpg Generated caption: a drawing of a blonde girl in a green jacket and black top\n6013729.jpg Generated caption: a girl with horns and a book\n6016847.jpg Generated caption: a girl with long hair and blue eyes holding a cell phone\n6013950.jpg Generated caption: a girl with a cat ears and a hat\n6015613.jpg Generated caption: a girl sitting on a bed with her hand on her chin\n6016264.jpg Generated caption: a girl with long black hair and a brown shirt\n6015737.jpg Generated caption: a girl in a sailor outfit with a sword\n6015509.jpg Generated caption: a girl with white hair and purple eyes\n6016272.jpg Generated caption: a girl with long white hair and a black purse\n6015190.jpg Generated caption: a girl with purple hair sitting in a dark room\n6015744.jpg Generated caption: a girl with long hair and a white dress is holding a sword\n6015328.jpg Generated caption: a sexy anime girl in a swimsuit\n6016622.jpg Generated caption: a girl in a school uniform sitting on the floor\n6015263.jpg Generated caption: a girl with long pink hair and a white dress\n6014206.jpg Generated caption: a girl with white hair and a black dress\n6016837.jpg Generated caption: a girl in a white dress and black jacket\n6015959.jpg Generated caption: a girl with long pink hair and a white dress\n6015342.jpg Generated caption: a girl in a school uniform standing in front of a blackboard\n6016335.jpg Generated caption: a girl with long hair and a white shirt is standing in the sky\n6016128.jpg Generated caption: a girl in a white coat and green dress sitting on a white surface\n6016924.jpg Generated caption: a woman in a black outfit holding a knife\n6015627.jpg Generated caption: a girl in a blue dress and a white coat\n6014851.jpg Generated caption: a sexy anime girl with long black hair and a red book\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BlipProcessor, BlipForConditionalGeneration\nfrom PIL import Image\n\n# Load the image captioning model and processor\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\nmodel = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n\ndef generate_image_caption(image_path: str) -> str:\n    try:\n        # Open the image\n        image = Image.open(image_path)\n        inputs = processor(images=image, return_tensors=\"pt\")\n\n        # Generate image caption with adjusted parameters\n        out = model.generate(**inputs, max_length=150, num_beams=10, early_stopping=True, length_penalty=1.2)\n        caption = processor.decode(out[0], skip_special_tokens=True)\n\n        return caption\n    except Exception as e:\n        return f\"Error processing {image_path}: {e}\"\n\n# Example usage\nimage_path = '/kaggle/input/cartoon-dataset-new/cartoon_dataset/6015545.jpg'\ncaption = generate_image_caption(image_path)\nprint(\"Generated caption:\", caption)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:52:04.542442Z","iopub.execute_input":"2024-08-12T17:52:04.542892Z","iopub.status.idle":"2024-08-12T17:52:22.639258Z","shell.execute_reply.started":"2024-08-12T17:52:04.542851Z","shell.execute_reply":"2024-08-12T17:52:22.638178Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Generated caption: an anime girl with blue hair and a hat\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Calling the DeepDanBooru model:  \nModel Source:https://huggingface.co/skytnt/deepdanbooru_onnx","metadata":{}},{"cell_type":"code","source":"! pip install onnxruntime","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:52:22.640739Z","iopub.execute_input":"2024-08-12T17:52:22.641150Z","iopub.status.idle":"2024-08-12T17:52:34.247522Z","shell.execute_reply.started":"2024-08-12T17:52:22.641114Z","shell.execute_reply":"2024-08-12T17:52:34.245855Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: onnxruntime in /opt/conda/lib/python3.10/site-packages (1.18.1)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (15.0.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (23.5.26)\nRequirement already satisfied: numpy<2.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (21.3)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.13.0)\nRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime) (10.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime) (3.1.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport onnxruntime as rt\nfrom huggingface_hub import hf_hub_download\n\n# Download the ONNX model\ntagger_model_path = \"/kaggle/input/deepdanbooru/deepdanbooru.onnx\"\n\n# Create an ONNX Runtime session\ntagger_model = rt.InferenceSession(tagger_model_path, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\ntagger_model_meta = tagger_model.get_modelmeta().custom_metadata_map\ntagger_tags = eval(tagger_model_meta['tags'])\n\ndef tagger_predict(image, score_threshold):\n    s = 512\n    h, w = image.shape[:-1]\n    h, w = (s, int(s * w / h)) if h > w else (int(s * h / w), s)\n    ph, pw = s - h, s - w\n    image = cv2.resize(image, (w, h), interpolation=cv2.INTER_AREA)\n    image = cv2.copyMakeBorder(image, ph // 2, ph - ph // 2, pw // 2, pw - pw // 2, cv2.BORDER_REPLICATE)\n    image = image.astype(np.float32) / 255\n    image = image[np.newaxis, :]  # Adding batch dimension\n    probs = tagger_model.run(None, {\"input_1\": image})[0][0]\n    probs = probs.astype(np.float32)\n    res = \"\"\n    for prob, label in zip(probs.tolist(), tagger_tags):\n        if prob < score_threshold:\n            continue\n        res = res + ',' + label\n    return res\n\n# Read and process the image\nimg = cv2.imread('/kaggle/input/cartoon-dataset-new/cartoon_dataset/6015545.jpg')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# Perform prediction and print results\ntags = tagger_predict(img, 0.1)\nprint(tags)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:52:34.249670Z","iopub.execute_input":"2024-08-12T17:52:34.250154Z","iopub.status.idle":"2024-08-12T17:52:43.160754Z","shell.execute_reply.started":"2024-08-12T17:52:34.250107Z","shell.execute_reply":"2024-08-12T17:52:43.159262Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":",1boy,1girl,alternate_costume,animal_ears,animal_hat,aran_sweater,bangs,bare_shoulders,beige_sweater,beret,black_bow,black_headwear,black_legwear,blue_bow,blue_eyes,blue_hair,blush,bow,bowtie,brown_headwear,brown_legwear,brown_sweater,cardigan,closed_mouth,collared_shirt,cowboy_shot,eyebrows_visible_through_hair,fake_animal_ears,garter_straps,hair_between_eyes,hair_bow,hair_ornament,hair_scrunchie,hat,long_hair,long_sleeves,looking_at_viewer,low_ponytail,low_twintails,male_focus,miniskirt,off_shoulder,otoko_no_ko,plaid,plaid_skirt,pleated_skirt,pom_pom_(clothes),ponytail,red_bow,red_bowtie,red_ribbon,red_skirt,ribbed_sweater,ribbon,scrunchie,shirt,sidelocks,simple_background,skirt,sleeves_past_fingers,sleeves_past_wrists,solo,star_(symbol),star_in_eye,sweater,thighhighs,thighs,twintails,very_long_hair,virtual_youtuber,white_background,white_shirt,white_sweater,zettai_ryouiki,hoshimachi_suisei,rating:safe\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Call the deepdanbooru-onnx library:  \nReference: https://github.com/chinoll/deepdanbooru_onnx","metadata":{}},{"cell_type":"code","source":"! pip install deepdanbooru-onnx","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:52:43.163903Z","iopub.execute_input":"2024-08-12T17:52:43.164345Z","iopub.status.idle":"2024-08-12T17:52:54.565757Z","shell.execute_reply.started":"2024-08-12T17:52:43.164306Z","shell.execute_reply":"2024-08-12T17:52:54.564399Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: deepdanbooru-onnx in /opt/conda/lib/python3.10/site-packages (0.0.8)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from deepdanbooru-onnx) (1.16.1)\nRequirement already satisfied: onnxruntime in /opt/conda/lib/python3.10/site-packages (from deepdanbooru-onnx) (1.18.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from deepdanbooru-onnx) (4.66.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from deepdanbooru-onnx) (1.26.4)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from deepdanbooru-onnx) (9.5.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from deepdanbooru-onnx) (2.32.3)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx->deepdanbooru-onnx) (3.20.3)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime->deepdanbooru-onnx) (15.0.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime->deepdanbooru-onnx) (23.5.26)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime->deepdanbooru-onnx) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime->deepdanbooru-onnx) (1.13.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->deepdanbooru-onnx) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->deepdanbooru-onnx) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->deepdanbooru-onnx) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->deepdanbooru-onnx) (2024.7.4)\nRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime->deepdanbooru-onnx) (10.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime->deepdanbooru-onnx) (3.1.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime->deepdanbooru-onnx) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from deepdanbooru_onnx import DeepDanbooru\nfrom PIL import Image\n\n# Initialize the DeepDanbooru model\ndanbooru = DeepDanbooru(threshold=0.1)\n\n# Load the image\nimg = Image.open('/kaggle/input/sd-pic1/2.jpg')\n\n# Process the image and get the tags with their scores\nresults = danbooru(img)\nprint(results)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:52:54.567968Z","iopub.execute_input":"2024-08-12T17:52:54.568487Z","iopub.status.idle":"2024-08-12T17:53:01.631172Z","shell.execute_reply.started":"2024-08-12T17:52:54.568431Z","shell.execute_reply":"2024-08-12T17:53:01.630053Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"{'1girl': 0.99454045, '3d': 0.14912981, 'artist_name': 0.18400699, 'bag': 0.16623747, 'bare_shoulders': 0.5645459, 'beach': 0.7505821, 'belt': 0.1776819, 'black_eyes': 0.23530883, 'black_hair': 0.3795284, 'blouse': 0.10615876, 'blue_eyes': 0.14631477, 'blue_sky': 0.1007711, 'blurry': 0.9993719, 'blurry_background': 0.9957928, 'blurry_foreground': 0.5013927, 'bokeh': 0.36695987, 'bra_strap': 0.5022479, 'breasts': 0.37781027, 'brown_eyes': 0.20224959, 'brown_hair': 0.41634795, 'buttons': 0.5361794, 'closed_mouth': 0.13623005, 'cloudy_sky': 0.103054136, 'collarbone': 0.26827747, 'contrapposto': 0.12131804, 'cosplay_photo': 0.12530622, 'cowboy_shot': 0.41487285, 'crop_top': 0.43415436, 'dappled_sunlight': 0.10887304, 'day': 0.5453065, 'denim': 0.9373488, 'denim_shorts': 0.728266, 'denim_skirt': 0.30981198, 'depth_of_field': 0.99547046, 'earrings': 0.9028425, 'eyelashes': 0.13505292, 'forehead': 0.31342736, 'grass': 0.10821122, 'handbag': 0.12803611, 'hoop_earrings': 0.14707333, 'jewelry': 0.8754506, 'lake': 0.38123518, 'lips': 0.8154957, 'lipstick': 0.2319687, 'long_hair': 0.7477842, 'looking_at_viewer': 0.57165205, 'looking_to_the_side': 0.116628975, 'makeup': 0.25534087, 'medium_breasts': 0.20570198, 'midriff': 0.6345164, 'mole': 0.22987694, 'mole_under_eye': 0.16884136, 'motion_blur': 0.457656, 'navel': 0.58491623, 'nose': 0.34777066, 'ocean': 0.65418756, 'off-shoulder_shirt': 0.5083354, 'off_shoulder': 0.69251627, 'open_mouth': 0.10295001, 'outdoors': 0.90435517, 'palm_tree': 0.16368556, 'parted_lips': 0.104054004, 'photo_(medium)': 0.62277895, 'photo_background': 0.40978837, 'photorealistic': 0.29464978, 'realistic': 0.84539175, 'red_lips': 0.31336796, 'river': 0.5741267, 'road': 0.14019057, 'sand': 0.115229815, 'shirt': 0.36053342, 'shore': 0.14457747, 'short_shorts': 0.4604833, 'short_sleeves': 0.16921407, 'shorts': 0.8716476, 'signature': 0.33407864, 'skirt': 0.10269073, 'skirt_tug': 0.11299357, 'sky': 0.24294958, 'smile': 0.5642701, 'solo': 0.9291969, 'standing': 0.40166625, 'stud_earrings': 0.11517048, 'thighs': 0.118162125, 'tree': 0.32255727, 'unbuttoned': 0.10282442, 'wading': 0.44042215, 'water': 0.8176024, 'white_shirt': 0.24577945, 'wind': 0.144108, 'rating:safe': 0.94092965}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"调用原作者模型：https://github.com/KichangKim/DeepDanbooru/releases/tag/v3-20211112-sgd-e28\n\n参考：https://colab.research.google.com/github/Skylion007/StyleGAN-notebooks/blob/main/StyleGAN_of_Anime_Sliders_by_Skyli0n.ipynb#scrollTo=H7T7nNrOmvXu","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport cv2\nimport json\n\nPATH = '/kaggle/input/deepdanbooru-model'\n# Load the pre-trained model\nmodelDeepdanbooru = tf.keras.models.load_model(PATH + '/model-resnet_custom_v3.h5', compile=True)\n\n\n# Function to load tags from a text file\ndef load_tags(tags_path):\n    with open(tags_path, 'r') as tags_stream:\n        tags = [tag.strip() for tag in tags_stream if tag.strip()]\n    return tags\n\n# Load tags into a numpy array\ntags = np.asarray(load_tags(PATH + '/tags.txt'))\n\n# Image preprocessing size\nDD_INPUT_SIZE = 512\n\n# Preprocess image function\ndef preprocess_image(image_path):\n    # Read and resize image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (DD_INPUT_SIZE, DD_INPUT_SIZE), interpolation=cv2.INTER_AREA)\n\n    # Normalize the image\n    image = image.astype(np.float32) / 255.0\n\n    # Expand dimensions to match model input shape\n    image = np.expand_dims(image, 0)\n    return image\n\n\n# Predict tags for a single image\ndef predict_tags(image_path, model, tags, threshold=0.5):\n    # Preprocess the image\n    image = preprocess_image(image_path)\n\n    # Predict\n    prediction = model.predict(image)[0]\n\n    # Filter tags based on threshold\n    predicted_tags = [tag for tag, prob in zip(tags, prediction) if prob > threshold]\n    tags_string = ', '.join(predicted_tags)  # Convert list of tags to a comma-separated string\n\n    return tags_string\n\n\n# Example usage\nimage_path = '/kaggle/input/cartoon-dataset-new/cartoon_dataset/6015545.jpg' # Path to your image file\npredicted_tags = predict_tags(image_path, modelDeepdanbooru, tags, 0.1)\n\n# Print or save the predicted tags\nprint(predicted_tags)\n\n# Optionally, you can save the predictions to a JSON file\n# with open('/kaggle/working/predictions.json', 'w') as f:\n#     json.dump({\"file_name\": image_path, \"tags\": predicted_tags}, f, ensure_ascii=False, indent=4)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:53:01.633166Z","iopub.execute_input":"2024-08-12T17:53:01.633610Z","iopub.status.idle":"2024-08-12T17:53:17.674931Z","shell.execute_reply.started":"2024-08-12T17:53:01.633581Z","shell.execute_reply":"2024-08-12T17:53:17.673914Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n1boy, 1girl, alternate_costume, animal_ears, aran_sweater, bangs, beret, black_bow, black_headwear, black_legwear, blue_bow, blue_eyes, blue_hair, blush, bow, bowtie, brown_legwear, brown_sweater, cardigan, closed_mouth, collared_shirt, dress, eyebrows_visible_through_hair, garter_belt, garter_straps, hair_between_eyes, hair_bow, hair_ornament, hair_ribbon, hat, long_hair, long_sleeves, looking_at_viewer, low-tied_long_hair, low_twintails, male_focus, off_shoulder, otoko_no_ko, plaid, plaid_dress, plaid_headwear, plaid_skirt, pleated_skirt, red_bow, red_bowtie, red_ribbon, red_skirt, ribbon, shirt, sidelocks, simple_background, sitting, skirt, sleeves_past_fingers, sleeves_past_wrists, solo, star_(symbol), star_hair_ornament, star_in_eye, star_print, sweater, thighhighs, thighs, twintails, very_long_hair, virtual_youtuber, white_background, white_shirt, hoshimachi_suisei, rating:safe\n","output_type":"stream"}]},{"cell_type":"code","source":"def analyze_image(image_path: str) -> dict:\n    # 示例使用\n    caption = generate_image_caption(image_path)\n    predicted_tags = predict_tags(image_path, modelDeepdanbooru, tags, 0.1)\n    return {\n        \"tags\": predicted_tags,\n        \"caption\": caption\n    }\n\n# Example usage\nimage_path = '/kaggle/input/cartoon-dataset-new/cartoon_dataset/6015545.jpg'  # Path to your image file\nresult = analyze_image(image_path)\n\n# Print or save the result\nprint(\"Blip:\", result[\"tags\"])\nprint(\"Deepdanbooru:\", result[\"caption\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:53:17.676385Z","iopub.execute_input":"2024-08-12T17:53:17.676745Z","iopub.status.idle":"2024-08-12T17:53:34.670387Z","shell.execute_reply.started":"2024-08-12T17:53:17.676718Z","shell.execute_reply":"2024-08-12T17:53:34.669176Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835ms/step\nBlip: 1boy, 1girl, alternate_costume, animal_ears, aran_sweater, bangs, beret, black_bow, black_headwear, black_legwear, blue_bow, blue_eyes, blue_hair, blush, bow, bowtie, brown_legwear, brown_sweater, cardigan, closed_mouth, collared_shirt, dress, eyebrows_visible_through_hair, garter_belt, garter_straps, hair_between_eyes, hair_bow, hair_ornament, hair_ribbon, hat, long_hair, long_sleeves, looking_at_viewer, low-tied_long_hair, low_twintails, male_focus, off_shoulder, otoko_no_ko, plaid, plaid_dress, plaid_headwear, plaid_skirt, pleated_skirt, red_bow, red_bowtie, red_ribbon, red_skirt, ribbon, shirt, sidelocks, simple_background, sitting, skirt, sleeves_past_fingers, sleeves_past_wrists, solo, star_(symbol), star_hair_ornament, star_in_eye, star_print, sweater, thighhighs, thighs, twintails, very_long_hair, virtual_youtuber, white_background, white_shirt, hoshimachi_suisei, rating:safe\nDeepdanbooru: an anime girl with blue hair and a hat\n","output_type":"stream"}]}]}